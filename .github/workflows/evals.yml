name: Evals

on:
  # Run on demand
  workflow_dispatch:
    inputs:
      scenario:
        description: 'Specific scenario to run (leave empty for all)'
        required: false
        default: ''
      parallel:
        description: 'Run scenarios in parallel'
        type: boolean
        default: false
  # Run on PRs and main branch pushes
  push:
    branches: [main]
  pull_request:
    branches: [main]
  # Run weekly to keep cache warm and catch regressions
  schedule:
    - cron: '0 0 * * 0'  # Every Sunday at midnight UTC

env:
  CARGO_TERM_COLOR: always
  CARGO_INCREMENTAL: 0
  CARGO_NET_RETRY: 10
  RUSTUP_MAX_RETRIES: 10

jobs:
  evals:
    name: Evals (${{ matrix.provider }})
    runs-on: linux-arm64
    strategy:
      fail-fast: false
      matrix:
        provider: [vertex-claude, openai, zai]

    steps:
      - uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable

      - name: Cache Cargo
        uses: Swatinem/rust-cache@v2
        with:
          workspaces: backend
          shared-key: rust-arm64
          cache-targets: true
          save-if: true
          cache-on-failure: true

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential pkg-config libssl-dev jq

      - name: Setup Vertex AI credentials
        run: |
          echo '${{ secrets.VERTEX_AI_CREDENTIALS }}' > /tmp/vertex-credentials.json

      - name: Build CLI with evals
        working-directory: backend
        run: cargo build --no-default-features --features evals --bin qbit-cli

      - name: List scenarios
        working-directory: backend
        run: ./target/debug/qbit-cli --list-scenarios

      - name: Run evals
        working-directory: backend
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ZAI_API_KEY: ${{ secrets.ZAI_API_KEY }}
          VERTEX_AI_PROJECT_ID: ${{ vars.VERTEX_AI_PROJECT_ID }}
          VERTEX_AI_LOCATION: ${{ vars.VERTEX_AI_LOCATION || 'us-east5' }}
          GOOGLE_APPLICATION_CREDENTIALS: /tmp/vertex-credentials.json
        run: |
          set -o pipefail

          PARALLEL_FLAG=""
          if [ "${{ github.event.inputs.parallel }}" = "true" ]; then
            PARALLEL_FLAG="--parallel"
          fi

          if [ -n "${{ github.event.inputs.scenario }}" ]; then
            ./target/debug/qbit-cli --eval --eval-provider "${{ matrix.provider }}" --scenario "${{ github.event.inputs.scenario }}" --json --verbose $PARALLEL_FLAG | tee eval-results.json
          else
            ./target/debug/qbit-cli --eval --eval-provider "${{ matrix.provider }}" --json --verbose $PARALLEL_FLAG | tee eval-results.json
          fi

      - name: Format results
        if: always()
        working-directory: backend
        run: |
          if [ -f eval-results.json ]; then
            echo "═══════════════════════════════════════════════════════════════"
            echo "                    EVAL RESULTS SUMMARY"
            echo "═══════════════════════════════════════════════════════════════"
            echo ""
            jq -r '"Provider: ${{ matrix.provider }}"' eval-results.json
            jq -r '"Total: \(.total) | Passed: \(.passed) | Failed: \(.failed) | Pass Rate: \((.pass_rate * 100 | floor))%"' eval-results.json
            echo ""
            echo "───────────────────────────────────────────────────────────────"
            echo "SCENARIOS:"
            echo "───────────────────────────────────────────────────────────────"
            jq -r '.scenarios[] | if .passed then "  ✓ \(.scenario)" else "  ✗ \(.scenario)" end' eval-results.json
            echo ""

            # Show details for failed scenarios
            FAILED=$(jq -r '.scenarios[] | select(.passed == false) | .scenario' eval-results.json)
            if [ -n "$FAILED" ]; then
              echo "═══════════════════════════════════════════════════════════════"
              echo "                    FAILED SCENARIO DETAILS"
              echo "═══════════════════════════════════════════════════════════════"
              jq -r '.scenarios[] | select(.passed == false) | "\n[\(.scenario)]\n  Metrics:\(.metrics[] | "\n    - \(.name): \(.status)\(if .details then " (\(.details))" else "" end)\(if .value then " (score: \(.value)/\(.max))" else "" end)")"' eval-results.json
            fi
          fi

      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: eval-results-${{ matrix.provider }}
          path: backend/eval-results.json
          if-no-files-found: ignore

      - name: Cleanup credentials
        if: always()
        run: rm -f /tmp/vertex-credentials.json
