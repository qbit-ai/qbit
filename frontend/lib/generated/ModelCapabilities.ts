// This file was generated by [ts-rs](https://github.com/Aleph-Alpha/ts-rs). Do not edit this file manually.

/**
 * Capabilities that vary across LLM models.
 *
 * This struct provides explicit metadata about what a model supports,
 * replacing runtime string-matching heuristics.
 */
export type ModelCapabilities = {
  /**
   * Whether the model supports the temperature parameter.
   *
   * Most models support temperature, but OpenAI reasoning models (o1, o3, gpt-5)
   * and codex models do not.
   */
  supports_temperature: boolean;
  /**
   * Whether thinking/reasoning should be tracked in message history.
   *
   * Models that produce reasoning traces that should be preserved:
   * - Anthropic: All models (extended thinking feature)
   * - OpenAI: Reasoning models (o1, o3, gpt-5 series)
   * - Gemini: gemini-2.0-flash-thinking-exp
   */
  supports_thinking_history: boolean;
  /**
   * Whether the model supports image/vision inputs.
   */
  supports_vision: boolean;
  /**
   * Whether the model supports native web search tools.
   */
  supports_web_search: boolean;
  /**
   * Whether this is a reasoning model (uses OpenAI reasoning client).
   *
   * Reasoning models (o1, o3, o4, gpt-5) have explicit reasoning events
   * that must be handled separately from text deltas.
   */
  is_reasoning_model: boolean;
  /**
   * Whether this is a coding-optimized model (codex variants).
   */
  is_codex_model: boolean;
  /**
   * Context window size in tokens.
   */
  context_window: number;
  /**
   * Maximum output tokens.
   */
  max_output_tokens: number;
};
